{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b03ccc2a",
      "metadata": {
        "id": "b03ccc2a"
      },
      "source": [
        "# Introduction to Computer Vision with PyTorch\n",
        "\n",
        "## 1. What is Computer Vision?\n",
        "\n",
        "Computer vision is a field of artificial intelligence (AI) that enables machines to interpret and make decisions based on visual data - such as images and videos - much like humans do. From recognizing faces in photos to enabling self-driving cars to detect pedestrians, computer vision is at the heart of many modern applications. It combines image processing, pattern recognition, and deep learning to extract meaningful information from raw pixel data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using Convolutional Neural Networks for our tasks. We are not really going to go into the details of the architectures and functioning of these networks - it's out of the scope of this course - but you can find details at **entropic theory of information**.\n"
      ],
      "metadata": {
        "id": "FrAHDlFaMHLT"
      },
      "id": "FrAHDlFaMHLT"
    },
    {
      "cell_type": "markdown",
      "id": "e762fcba",
      "metadata": {
        "id": "e762fcba"
      },
      "source": [
        "Before starting to code for real, let's have a look at some important libraries we may want to use for computer vision problems.\n",
        "\n",
        "| PyTorch module              | What does it do?                                                                                                                                                             |\n",
        "|----------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| [`torchvision`](https://docs.pytorch.org/vision/stable/index.html#torchvision)              | Contains datasets, model architectures and image transformations often used for computer vision problems.                                                                  |\n",
        "| [`torchvision.datasets`](https://docs.pytorch.org/vision/stable/datasets.html#datasets)     | Here you'll find many example computer vision datasets for a range of problems from image classification, object detection, image captioning, video classification and more. It also contains [a series of base classes for making custom datasets](https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets). |\n",
        "| [`torchvision.models`](https://docs.pytorch.org/vision/stable/models.html#models-and-pre-trained-weights)       | This module contains well-performing and commonly used computer vision model architectures implemented in PyTorch, you can use these with your own problems.                |\n",
        "| [`torchvision.transforms`](https://docs.pytorch.org/vision/stable/transforms.html#transforming-and-augmenting-images)   | Often images need to be transformed (turned into numbers/processed/augmented) before being used with a model, common image transformations are found here.                 |\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# check versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "id": "cZ5oAmRhO88L"
      },
      "id": "cZ5oAmRhO88L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Get a Dataset\n",
        "\n",
        "We want to use the [`FashionMNIST`](https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#fashionmnist) dataset from `torchvision.datasets`"
      ],
      "metadata": {
        "id": "ySJxfzeUPulj"
      },
      "id": "ySJxfzeUPulj"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download data to\n",
        "    train=True, # do we want the training datasets or the test?\n",
        "    download=True, # do we want to download it?\n",
        "    transform=ToTensor(),  # what kind of transformation do we want to apply on data?\n",
        "    target_transform=None # how do we want to transform the labels (targets) ?\n",
        ")"
      ],
      "metadata": {
        "id": "UP4pRbC6RCWz"
      },
      "id": "UP4pRbC6RCWz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup testing data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where to download data to\n",
        "    train=False, # do we want the training datasets or the test?\n",
        "    download=True, # do we want to download it?\n",
        "    transform=ToTensor(),  # what kind of transformation do we want to apply on data?\n",
        "    target_transform=None # how do we want to transform the labels (targets) ?\n",
        ")"
      ],
      "metadata": {
        "id": "JPVHCAEuRnE-"
      },
      "id": "JPVHCAEuRnE-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check out our data"
      ],
      "metadata": {
        "id": "9V2R3oczRuuj"
      },
      "id": "9V2R3oczRuuj"
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "kPQeZjn8R73Y"
      },
      "id": "kPQeZjn8R73Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the first training example\n",
        "image, label = train_data[0]\n",
        "image"
      ],
      "metadata": {
        "id": "LbSOIJ4_R-NP"
      },
      "id": "LbSOIJ4_R-NP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like the `ToTensor()` transform did its work."
      ],
      "metadata": {
        "id": "zyW6watgSIOC"
      },
      "id": "zyW6watgSIOC"
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "C7AzQXUFSU4_"
      },
      "id": "C7AzQXUFSU4_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "FmHbkyDvSl7a"
      },
      "id": "FmHbkyDvSl7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "X7QNwaBbSrJW"
      },
      "id": "X7QNwaBbSrJW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shapes\n",
        "print(f\"Image shape: {image.shape} <- [color_channels, height, width];\\nImage label: {label}\")"
      ],
      "metadata": {
        "id": "QaA3VlnUSv5C"
      },
      "id": "QaA3VlnUSv5C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **(!!) Note:** PyTorch uses the **CHW** format for images, meaning the dimensions are ordered as **Channels × Height × Width**. When working with batches of images, the format becomes **NCHW**, where **N** is the batch size. This is different from many image libraries like PIL or OpenCV, which use **HWC** format. Make sure to convert your image tensors accordingly when feeding them into a model.\n"
      ],
      "metadata": {
        "id": "38xabZK5SzCc"
      },
      "id": "38xabZK5SzCc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why just one color? Well, the MNIST dataset is composed of black and white images, so just one channel."
      ],
      "metadata": {
        "id": "DAO-MbUATH1h"
      },
      "id": "DAO-MbUATH1h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Example of encoding an RGB image](https://github.com/MatteoFalcioni/PyTorch_basics/blob/main/imgs/03-fashion-mnist-slide.png?raw=1)"
      ],
      "metadata": {
        "id": "GpCm9AITUGSz"
      },
      "id": "GpCm9AITUGSz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Visualize our Data"
      ],
      "metadata": {
        "id": "dw7hjTLmU2B5"
      },
      "id": "dw7hjTLmU2B5"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.permute(1,2,0))  # change from CHW -> HWC (torch format -> python format)\n",
        "plt.title(label)"
      ],
      "metadata": {
        "id": "EE-mYdxPVKbW"
      },
      "id": "EE-mYdxPVKbW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in gray scale\n",
        "plt.imshow(image.permute(1,2,0), cmap=\"gray\")\n",
        "plt.title(f\"{label} : {class_names[label]}\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "tkem7qdAVz2q"
      },
      "id": "tkem7qdAVz2q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot more (random) images\n",
        "torch.manual_seed(123)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows*cols+1):\n",
        "  random_idx  = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.permute(1,2,0), cmap=\"gray\")\n",
        "  plt.title(f\"{label} : {class_names[label]}\")\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "hu5mNKEKWi17"
      },
      "id": "hu5mNKEKWi17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare a Dataloader"
      ],
      "metadata": {
        "id": "iCqDreiSXZTK"
      },
      "id": "iCqDreiSXZTK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, a [`Dataloader`](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html#datasets-dataloaders) is a powerful utility that provides an efficient way to iterate over a dataset. It wraps a dataset object (typically a subclass of `torch.utils.data.Dataset`) and returns data in manageable **batches**, optionally shuffling the data and loading it in parallel using multiple worker processes.\n",
        "\n",
        "DataLoaders are Python iterables, which means you can loop over them using a `for` loop to retrieve batches of data. Each iteration yields a tuple (usually `(inputs, labels)`) that can be fed into a model for training or evaluation. By handling batching, shuffling, and multiprocessing under the hood, DataLoaders streamline the data pipeline and allow you to focus on model development.\n",
        "\n",
        "We said that we want to turn our model into *batches* (or minibatches). Why is that? Because\n",
        "\n",
        "1. The memory resources of a machine are limited, and it generally can't manage to process all the dataset at once, so deviding into batches is more computionally efficient.\n",
        "\n",
        "2. It gives our neural network more chances to update the gradient at each epoch.\n",
        "\n",
        "We want to create batches of size $32$ - this is a customizable number, you could use $16$, $64$, $8$..."
      ],
      "metadata": {
        "id": "rH9B7_xwYksb"
      },
      "id": "rH9B7_xwYksb"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# batch size\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# turn datasets into iterable (batches)\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True) # shuffle train data to mix order\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=False) # no need to shuffle eval data"
      ],
      "metadata": {
        "id": "zuxYQaFd36Ln"
      },
      "id": "zuxYQaFd36Ln",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what's inside the Datsaloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader)) # since our dataloader\n",
        "train_features_batch.shape, train_labels_batch.shape\n"
      ],
      "metadata": {
        "id": "kaP8Pl-X6A6M"
      },
      "id": "kaP8Pl-X6A6M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.permute(1,2,0), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ],
      "metadata": {
        "id": "U37kzcuO7LCu"
      },
      "id": "U37kzcuO7LCu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Build a baseline model\n",
        "\n",
        "A baseline model is a simple model you will try and improve upon with subsequent models/ experiments (starts simple, then add complexity)."
      ],
      "metadata": {
        "id": "RwzEKhG16rnl"
      },
      "id": "RwzEKhG16rnl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a flatten layer\n",
        "\n",
        "flatten_model = nn.Flatten()\n",
        "\n",
        "# Get a single sample\n",
        "\n",
        "x = train_features_batch[0]\n",
        "x.shape"
      ],
      "metadata": {
        "id": "pVFxSa668qN6"
      },
      "id": "pVFxSa668qN6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the sample...\n",
        "output = flatten_model(x)\n",
        "\n",
        "print(f\"Shape before flattening: {x.shape} -> shape after flattening: {output.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YIDgXHWm9gST"
      },
      "id": "YIDgXHWm9gST",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `nn.Flatten()` layer literally flattens a contiguous range of dims into a tensor. By default it starts by dim=1 (not 0) and ends at the last. So if we squeeze we get"
      ],
      "metadata": {
        "id": "qNJRiub29nbw"
      },
      "id": "qNJRiub29nbw"
    },
    {
      "cell_type": "code",
      "source": [
        "(output.squeeze()).shape"
      ],
      "metadata": {
        "id": "bORwEE-G-V_l"
      },
      "id": "bORwEE-G-V_l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use it in order to feed this flattened output to successive linear layers, since these expect vectors, not 2D grids."
      ],
      "metadata": {
        "id": "g5OOiq5CCKRZ"
      },
      "id": "g5OOiq5CCKRZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create the V0 model:\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape : int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape,\n",
        "                  out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)\n"
      ],
      "metadata": {
        "id": "IbZeWkTL-a2P"
      },
      "id": "IbZeWkTL-a2P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model_0 = FashionMNISTModelV0(input_shape=784,  # 28*28\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "wpW3UUBo-2sZ"
      },
      "id": "wpW3UUBo-2sZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = torch.rand([1, 1, 28, 28]).to(device)  # 1 example of shape 1x28x28\n",
        "model_0(dummy_x).shape  # 1 logit per class"
      ],
      "metadata": {
        "id": "0zfyX1kZBOYI"
      },
      "id": "0zfyX1kZBOYI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Setup  loss, optimizer and metrics\n",
        "\n",
        "* Since we are in multiclass classification we will use `CrossEntropyLoss()`\n",
        "* For the optimizer we'll stick with `torch.optim.SGD()`\n",
        "* Evaluation metric: since we are facing a classification problem, we will use accuracy."
      ],
      "metadata": {
        "id": "4hHGO-kT-2ax"
      },
      "id": "4hHGO-kT-2ax"
    },
    {
      "cell_type": "code",
      "source": [
        "# We could use torchmetrics but let's use a custom one for now, to see how we import from github\n",
        "\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "59n3EGX3DDr1"
      },
      "id": "59n3EGX3DDr1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import accuracy metric\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "# Setup Loss and Optimizer\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)\n"
      ],
      "metadata": {
        "id": "NxJBLmQ1DjOI"
      },
      "id": "NxJBLmQ1DjOI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Creating a function to time our experiments\n",
        "\n",
        "We usually want to time how long our training takes:"
      ],
      "metadata": {
        "id": "woN8EUAn-ViR"
      },
      "id": "woN8EUAn-ViR"
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end : float,\n",
        "                     device : torch.device=None):\n",
        "  \"\"\"\n",
        "  Prints difference between start and end time\n",
        "  \"\"\"\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "eZxuTd2D9ZFh"
      },
      "id": "eZxuTd2D9ZFh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timer()\n",
        "# some code ...\n",
        "end_time = timer()\n",
        "print_train_time(start=start_time, end=end_time, device=device)"
      ],
      "metadata": {
        "id": "5L95Nf7D98CI"
      },
      "id": "5L95Nf7D98CI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Training Loop"
      ],
      "metadata": {
        "id": "TZqKgeMF-dQr"
      },
      "id": "TZqKgeMF-dQr"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# set the seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "9cS6t-Q1AMht"
      },
      "id": "9cS6t-Q1AMht",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataloader, test_dataloader, num_epochs, loss_fn, optimizer, device):\n",
        "  \"\"\"\n",
        "  Trains and tests the given model, by:\n",
        "  1. Looping through epochs\n",
        "  2. Looping through training batches -> performs training step -> calculates train loss *per batch*\n",
        "  3. Looping through test batches -> performs test step -> calculates test loss *per batch*\n",
        "\n",
        "  Args:\n",
        "    - model (torch.nn.Module): the model to train\n",
        "    - train_dataloader (torch.utils.data.Dataloader): torch Dataloader containing training data\n",
        "    - test_dataloader (torch.utils.data.Dataloader): torch Dataloader containing test data\n",
        "    - num_epochs (int): number of epochs to train the model for\n",
        "    - device () : the device to run the training on\n",
        "\n",
        "  Returns:\n",
        "    - train_losses, test_losses, accuracies (lists): lists containing training loss, test loss and accuracies, averaged over batches\n",
        "\n",
        "  \"\"\"\n",
        "  # to store data\n",
        "  train_losses, test_losses, accuracies = [], [], []\n",
        "\n",
        "  # Train and test loop\n",
        "  for epoch in tqdm(range(num_epochs)): # loop through epochs\n",
        "\n",
        "    print(f\"------------\\nEpoch [{epoch}/{num_epochs}]\")\n",
        "\n",
        "    train_loss = 0  # to accumulate loss *per batch*\n",
        "\n",
        "    ## Train loop through batches\n",
        "    for batch, (X_train, y_train) in enumerate(train_dataloader):\n",
        "\n",
        "      X_train = X_train.to(device)\n",
        "      y_train = y_train.to(device)\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      # 1. forward pass\n",
        "      y_pred = model(X_train)\n",
        "\n",
        "      # 2. compute loss\n",
        "      loss = loss_fn(y_pred, y_train)\n",
        "      train_loss += loss  # accumulate train loss\n",
        "\n",
        "      # 3. zero out the gradient\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. backward pass\n",
        "      loss.backward()\n",
        "\n",
        "      # 5. step the optimizer\n",
        "      optimizer.step()\n",
        "\n",
        "      if batch % 400 == 0:\n",
        "        print(f\"Processed {batch * len(X_train) / len(train_dataloader.dataset):.3f}% of samples\")\n",
        "\n",
        "    # Divide total train loss by the length of the train dataloader to average over batches\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    ## Testing\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "      ## Test loop through batches\n",
        "      for X_test, y_test in test_dataloader:\n",
        "        X_test = X_test.to(device)\n",
        "        y_test = y_test.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        test_pred = model(X_test)\n",
        "\n",
        "        # Compute and cumulate loss\n",
        "        test_loss += loss_fn(test_pred, y_test)\n",
        "        accuracy += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=-1)) # careful, preds need argmax to go from logits to preds\n",
        "\n",
        "      # average test loss and accuracy over batches\n",
        "      test_loss /= len(test_dataloader)\n",
        "      accuracy /= len(test_dataloader)\n",
        "\n",
        "    # keep track of losses and accuracy over epochs\n",
        "    train_losses.append(train_loss.item())\n",
        "    test_losses.append(test_loss.item())\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\">>> Accuracy: {accuracy}\")\n",
        "\n",
        "  return train_losses, test_losses, accuracies\n"
      ],
      "metadata": {
        "id": "jBIIpkAbD8jQ"
      },
      "id": "jBIIpkAbD8jQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's train!\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "start_time = timer()\n",
        "train_losses, test_losses, accuracies = train_model(model=model_0,\n",
        "                                                    train_dataloader=train_dataloader,\n",
        "                                                    test_dataloader=test_dataloader,\n",
        "                                                    num_epochs=NUM_EPOCHS,\n",
        "                                                    loss_fn=loss_fn,\n",
        "                                                    optimizer=optimizer,\n",
        "                                                    device=device)\n",
        "end_time = timer()\n",
        "print_train_time(start=start_time, end=end_time, device=device)"
      ],
      "metadata": {
        "id": "89-ULEyfHwnd"
      },
      "id": "89-ULEyfHwnd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print losses\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def print_losses(train_losses, test_losses, start_epoch=1):\n",
        "  \"\"\"\n",
        "  Prints losses and accuracy\n",
        "  \"\"\"\n",
        "\n",
        "  num_epochs = range(start_epoch, len(train_losses) + start_epoch)\n",
        "\n",
        "  plt.figure(figsize=(10,7))\n",
        "  plt.title(\"Train Loss vs Test Loss\")\n",
        "  plt.plot(num_epochs, train_losses, label=\"Train loss\")\n",
        "  plt.plot(num_epochs, test_losses, label=\"Test loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss values\")\n",
        "  plt.legend()\n"
      ],
      "metadata": {
        "id": "qtAePl1qIgIs"
      },
      "id": "qtAePl1qIgIs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_losses(train_losses, test_losses)"
      ],
      "metadata": {
        "id": "0jdFeARBLEAE"
      },
      "id": "0jdFeARBLEAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We slightly overfitted towards the end of training... but let's compute predicitons anyway to see if our model is outputting something good."
      ],
      "metadata": {
        "id": "ce_bu7MwGOdH"
      },
      "id": "ce_bu7MwGOdH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Make predictions\n",
        "\n",
        "We will functionize the evaluation loop as well, in order to be able to use it for the next models."
      ],
      "metadata": {
        "id": "WJUwrJ1KGVji"
      },
      "id": "WJUwrJ1KGVji"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "def eval_model(model: nn.Module,\n",
        "               eval_dataloader: DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device):\n",
        "  \"\"\"\n",
        "  Returns a dictionary of model predicting on eval_dataloader\n",
        "  \"\"\"\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "\n",
        "    for X, y in eval_dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      # make predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # Accumulate loss and accuracy per batch\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y,\n",
        "                         y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    # Average loss and accuracy over batches\n",
        "    loss /= len(eval_dataloader)\n",
        "    acc /= len(eval_dataloader)\n",
        "\n",
        "  return{\"model_name\": model.__class__.__name__,  # works when model was created with a class\n",
        "         \"model_loss\": loss.item(),\n",
        "         \"model_acc\": acc}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CJwZQ-QLGgfR"
      },
      "id": "CJwZQ-QLGgfR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate model 0 results on test dataset\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model_0_results = eval_model(model=model_0,\n",
        "                             eval_dataloader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             accuracy_fn=accuracy_fn,\n",
        "                             device=device)\n",
        "\n",
        "model_0_results"
      ],
      "metadata": {
        "id": "Sdb8RJKbIwIY"
      },
      "id": "Sdb8RJKbIwIY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Improvements: Add Non-Linearity\n",
        "\n",
        "We have good results, but trust me, we can do way better. Let's add non-linearity to our code."
      ],
      "metadata": {
        "id": "XkhNZiZlJXSA"
      },
      "id": "XkhNZiZlJXSA"
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               output_shape: int,\n",
        "               hidden_units: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),  # don't forget to flatten in convolutional NN!\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "29Pj3OnAJ1Iw"
      },
      "id": "29Pj3OnAJ1Iw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model_1 = FashionMNISTModelV1(input_shape=784,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)\n",
        "\n",
        "model_1"
      ],
      "metadata": {
        "id": "xYljZWaeLN6p"
      },
      "id": "xYljZWaeLN6p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Functionize Everything\n",
        "\n",
        "Let's functionize once and for good our training and testing loops:"
      ],
      "metadata": {
        "id": "f8YYnONAV6or"
      },
      "id": "f8YYnONAV6or"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's adapt the train function to use the eval function we created earlier\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               train_loader: DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device):\n",
        "  \"\"\"\n",
        "  Performs a training step with a given model\n",
        "  \"\"\"\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "\n",
        "  # training mode\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(train_loader):\n",
        "\n",
        "    # put data on target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # compute the loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    # accumulate loss and acc\n",
        "    train_loss += loss.item()\n",
        "    train_acc += accuracy_fn(y_true=y,\n",
        "                             y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    # zero out the gradient\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "  # average loss and accuracy over samples\n",
        "  train_loss /= len(train_loader)\n",
        "  train_acc /= len(train_loader)\n",
        "\n",
        "  print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\\n\")\n",
        "\n",
        "  return train_loss, train_acc"
      ],
      "metadata": {
        "id": "5k43Bb0WLx5A"
      },
      "id": "5k43Bb0WLx5A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              test_loader: DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device):\n",
        "  \"\"\"\n",
        "  performs a testing loop step on a given model\n",
        "  \"\"\"\n",
        "\n",
        "  # eval mode\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  test_acc = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "\n",
        "      # send to device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # get predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # accumulate losses\n",
        "      test_loss += loss_fn(y_pred, y).item()\n",
        "      test_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "    # average metrics\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc /= len(test_loader)\n",
        "\n",
        "    print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "    return test_loss, test_acc"
      ],
      "metadata": {
        "id": "7waWeTEPWAFF"
      },
      "id": "7waWeTEPWAFF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Dict, List, Tuple\n",
        "\n",
        "def train_epochs(model: torch.nn.Module,\n",
        "                 train_loader: DataLoader,\n",
        "                 test_loader: DataLoader,\n",
        "                 loss_fn: torch.nn.Module,\n",
        "                 optimizer: torch.optim.Optimizer,\n",
        "                 accuracy_fn : Callable[[torch.Tensor, torch.Tensor], float],\n",
        "                 device: torch.device,\n",
        "                 n_epochs: int\n",
        "                 ) -> Dict[str, List[float]]:\n",
        "  \"\"\"\n",
        "  Performs training and evaluation of the given model during several epochs.\n",
        "  \"\"\"\n",
        "\n",
        "  # lists to store metrics\n",
        "  train_losses, train_accuracies, test_losses, test_accuracies = [], [], [], []\n",
        "\n",
        "  for epoch in tqdm(range(n_epochs), desc=\"Training and testing...\"):\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} ------\")\n",
        "    # training step\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                        train_loader=train_loader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        optimizer=optimizer,\n",
        "                                        accuracy_fn=accuracy_fn,\n",
        "                                        device=device)\n",
        "\n",
        "    # test step\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    test_loader=test_loader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    accuracy_fn=accuracy_fn,\n",
        "                                    device=device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "  # return a dictionary of metrics\n",
        "  return {\"train_loss\": train_losses,\n",
        "          \"train_acc\": train_accuracies,\n",
        "          \"test_loss\": test_losses,\n",
        "          \"test_acc\": test_accuracies}\n",
        "\n"
      ],
      "metadata": {
        "id": "jjd5L6ggXwAA"
      },
      "id": "jjd5L6ggXwAA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = FashionMNISTModelV1(input_shape=784,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)\n",
        "\n",
        "optimizer=torch.optim.SGD(params=model_1.parameters(),\n",
        "                          lr=0.01)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "metrics_dict = train_epochs(model=model_1,\n",
        "                            train_loader=train_dataloader,\n",
        "                            test_loader=test_dataloader,\n",
        "                            loss_fn=loss_fn,\n",
        "                            optimizer=optimizer,\n",
        "                            accuracy_fn=accuracy_fn,\n",
        "                            device=device,\n",
        "                            n_epochs=3)\n",
        "\n",
        "metrics_dict"
      ],
      "metadata": {
        "id": "CvbDYihiZ3Pi"
      },
      "id": "CvbDYihiZ3Pi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wait, what? We didn't surpass the non linear model! Hhhmmmm..."
      ],
      "metadata": {
        "id": "QIbuobPsbFyC"
      },
      "id": "QIbuobPsbFyC"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNvoH_WfmSSv"
      },
      "id": "bNvoH_WfmSSv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}