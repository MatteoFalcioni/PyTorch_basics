{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8bd2834",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "## Introduction to Tensors\n",
    "\n",
    "At the core of PyTorch lies the `Tensor` object, which serves as the fundamental data structure for all computations. Tensors are multidimensional arrays, conceptually similar to NumPy arrays, but with added capabilities tailored for deep learning and high-performance computing.\n",
    "\n",
    "PyTorch tensors support a wide variety of operations, including arithmetic, indexing, reshaping, and broadcasting. More importantly, they can be transferred seamlessly between the CPU and GPU, allowing for accelerated computation with minimal code changes.\n",
    "\n",
    "In practice, tensors represent everything from scalar values to high-dimensional data such as images, sequences, and model parameters. Understanding tensors and how to manipulate them efficiently is essential for working with PyTorch and developing neural network models.\n",
    "\n",
    "PyTorch tensors are created using [`torch.tensor`](https://pytorch.org/docs/stable/tensors.html). For example, we may create the simplest tensor – a scalar – in the following way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18602581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# scalar\n",
    "scalar = torch.tensor(2)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b431478",
   "metadata": {},
   "source": [
    "A scalar is a $0$-dimensional tensor. As a matter of fact, we can check its dimension with `ndim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e539cbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c2e7c",
   "metadata": {},
   "source": [
    "To access the value of a tensor, we must use the `item()` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7fd344d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e600979",
   "metadata": {},
   "source": [
    "The next structure is just a vector, i.e. a tensor of dimension $2$. We can create it using the torch.tensor() constructor from a simple python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1909dd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 7])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "vector = torch.tensor([2, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b1d1a0",
   "metadata": {},
   "source": [
    "Note: be careful using `tensor()` instead of `Tensor()`. The latter is a lower-level class constructor. When given shape arguments (e.g., `torch.Tensor(2, 3)`), it creates an *uninitialized* tensor. This can lead to unintended behavior. So, always use `torch.tensor()` when starting from data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da9f98",
   "metadata": {},
   "source": [
    "Now, tensors' dimensions and their shapes are very important in PyTorch. When manipulating vectors, we must pay close attention to their shapes, or we may run into errors or miscalculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3f731ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b8257a",
   "metadata": {},
   "source": [
    "This is different from vector.shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9486433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8b565",
   "metadata": {},
   "source": [
    "We can step things up and create a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "286c2846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2], [7, 8]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d80c870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix dims: 2\n",
      "matrix shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"matrix dims: {matrix.ndim}\")\n",
    "print(f\"matrix shape: {matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50f56e",
   "metadata": {},
   "source": [
    "This tells us that our matrix is 2-dimensional, and in fact it's a 2×2 square matrix. How about a rectangular matrix? Very simple:\n",
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d20b739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix dims: 2\n",
      "matrix shape: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "rect_matrix = torch.tensor([[1, 2], [3, 4], [4, 5]])\n",
    "print(f\"matrix dims: {rect_matrix.ndim}\")\n",
    "print(f\"matrix shape: {rect_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dfd227",
   "metadata": {},
   "source": [
    "Since we have $2$ elements along each axes, and it's a $3\\times2$ matrix.  \n",
    "Let's see how it works with tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e78d97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5],\n",
       "         [6, 7, 8]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5],\n",
    "                        [6, 7, 8]]])\n",
    "TENSOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4c90cef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor dim: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor dim: {TENSOR.ndim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "64d4e967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor shape: {TENSOR.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56c5e0",
   "metadata": {},
   "source": [
    "Why this shape? We can think of tensors as multidimensional matrices. In this case, we have 1 matrix containing 4 vectors of dimension 3.\n",
    "\n",
    "Understanding shapes takes some practice, but once you get used to it, it becomes second nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa0e38",
   "metadata": {},
   "source": [
    "This represents 2 images, each of size 3×3 pixels, with 3 channels (RGB).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83790a27",
   "metadata": {},
   "source": [
    "## Random Tensors\n",
    "\n",
    "Random tensors are very important in PyTorch's workflows. The reason is the way Neural Networks work. They start from randomly initialized weights, and they adapt these values through training (by minimizing a Loss function). So the first step is always to intialize weights randomly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34775a6",
   "metadata": {},
   "source": [
    "In order to create random tensors we can use Torch's [torch.rand()](https://docs.pytorch.org/docs/main/generated/torch.rand.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2622a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random tensor dimension: 2\n",
      "random tensor shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor\n",
    "print(f\"random tensor dimension: {random_tensor.ndim}\") # dims will be 2\n",
    "print(f\"random tensor shape: {random_tensor.shape}\") # shape will be torch.Size([3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2f7cc",
   "metadata": {},
   "source": [
    "A common example of tensor encoding is when we want to encode an image. Usually to encode an image we use a tensor of shapes `[colour_channels, height, width]`. For an RGB image of size `224 x 224`we will use something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2671288",
   "metadata": {},
   "source": [
    "![Example of encoding an RGB image](imgs/00-tensor-shape-example-of-image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f1baf",
   "metadata": {},
   "source": [
    "## 0's and 1's Tensors\n",
    "These are useful for creating masks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "04ad6985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all zeros\n",
    "zeros = torch.zeros(3,4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "06ece2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all zeros\n",
    "ones = torch.ones(3,4)\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2096f",
   "metadata": {},
   "source": [
    "Note: when you let Torch automatically create a tensor, its default type is `torch.float32`. To get the type we can use the `.dtype` argument. We will see more about types in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac44c974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd8684",
   "metadata": {},
   "source": [
    "## Creating range of tensors & tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e880321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.range()\n",
    "one_to_Ten = torch.arange(1,11)\n",
    "one_to_Ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d91e3f",
   "metadata": {},
   "source": [
    "Basically its parameters are start, end (ends at end-1) and steps. by default the step is $1$ but we can modify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9dc1eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
       "        36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70,\n",
       "        72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_hundred = torch.arange(start=0, end=100, step=2)\n",
    "zero_to_hundred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfad46c",
   "metadata": {},
   "source": [
    "Another useful method is the `_like()` method. For example, `zeros_like()`  allows us to create a tensor with the shape of another already existing tensor, all filled with zeros. There are many options, you can fill it with chosen values (`torch.full_like()`) , with random numbers (`torch.rand_like()`), and so on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21a96f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros = torch.zeros_like(one_to_Ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b60249",
   "metadata": {},
   "source": [
    "## Tensor datatypes\n",
    "\n",
    "The standard type is float32, but we can change it of course by explicitly setting it. See [torch.dtype](https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch-dtype)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cbf9d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3513, 0.6349, 0.8420, 0.9925, 0.9101, 0.7914],\n",
       "        [0.1295, 0.1268, 0.9806, 0.1038, 0.3814, 0.0941]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.rand(2 ,6)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9c872521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92525e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 16 tensor\n",
    "float_16_tensor = torch.rand((2 ,6), dtype=torch.float16)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97a714",
   "metadata": {},
   "source": [
    "Or, if you are creating a tensor from scratch, you can specify it in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe5c56ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  6.,  9., 10.], dtype=torch.float16)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [3, 6, 9, 10]\n",
    "tensor = torch.tensor(data, dtype=torch.float16)\n",
    "tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a3f8e1",
   "metadata": {},
   "source": [
    "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "\n",
    "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
    "\n",
    "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ff7fb",
   "metadata": {},
   "source": [
    "`.dtype` is one of the three main arguments in the `tensor()` class. The other two are just as important - if not more - and we will see more about them later on. They are the `device` argument, which specify on which device (cpu or gpu) our machine should create our tensor, and `requires_grad`, which specifies if we should keep track of operations performed on our tensor in order to perform backpropagation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1334ef97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cpu'), False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # What dataype is the tensor, defaults to torch.float32 (even if it's set to None)\n",
    "                               device='cpu', # What device is your tensor on\n",
    "                               requires_grad=False) # whether or not to track gradients for backpropagation (default False if not wrapped in nn.Parameter)\n",
    "\n",
    "float_32_tensor.dtype, float_32_tensor.device, float_32_tensor.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58726ce0",
   "metadata": {},
   "source": [
    "Operations between types in Torch are robust, meaning that even if two tensors have different types, sometimes this will not raise an error, and revert everything to default (float 32). Nonetheless, you should always be careful to *perform operations between tensors of the same type*, to avoid miscalculations and problems.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f864985",
   "metadata": {},
   "source": [
    "## Getting Information from Tensors\n",
    "\n",
    "Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get some information from them.\n",
    "\n",
    "We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n",
    "- `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
    "- `dtype` - what datatype are the elements within the tensor stored in?\n",
    "- `device` - what device is the tensor stored on? (usually GPU or CPU) \n",
    "\n",
    "Let's create a random tensor and find out details about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232b4934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3923, 0.4521, 0.5415, 0.3870],\n",
      "        [0.9300, 0.6538, 0.9350, 0.3785],\n",
      "        [0.0193, 0.2008, 0.8574, 0.0714]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072755ef",
   "metadata": {},
   "source": [
    "## Basic Operations and Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e724688",
   "metadata": {},
   "source": [
    "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
    "\n",
    "A model learns by investigating those tensors and performing a series of operations (could be $1,000,000$'s+) on tensors to create a representation of the patterns in the input data.\n",
    "\n",
    "These operations are often a wonderful dance between:\n",
    "\n",
    "- Addition\n",
    "- Substraction\n",
    "- Multiplication (element-wise)\n",
    "- Division\n",
    "- Matrix multiplication\n",
    "\n",
    "And that's it. Sure there are a few more here and there but these are the basic building blocks of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb997c3",
   "metadata": {},
   "source": [
    "Let's start with a few of the fundamental operations, addition (`+`), subtraction (`-`), mutliplication (`*`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c976ac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7f9c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b0cf88",
   "metadata": {},
   "source": [
    "Notice how the tensor values above didn't end up being `tensor([110, 120, 130])`, this is because the values inside the tensor don't change unless they're reassigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f5eaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c22ec",
   "metadata": {},
   "source": [
    "Let's subtract a number and this time we'll reassign the tensor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87d24806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-19, -18, -17])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ec29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c16c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add and reassign\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d165f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f55852",
   "metadata": {},
   "source": [
    "### Note on Broadcasting \n",
    "\n",
    "Broadcasting allows PyTorch to perform operations between tensors of different shapes by automatically expanding the smaller tensor to match the shape of the larger one.\n",
    "\n",
    "For example what we saw above :\n",
    "```python\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c755f",
   "metadata": {},
   "source": [
    "PyTorch is *broadcasting* the scalar `10` across all elements of the tensor. Internally, it's as if it expanded `10` to match the shape of tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c309c8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent to:\n",
    "torch.tensor([1, 2, 3]) + torch.tensor([10, 10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e2f2d",
   "metadata": {},
   "source": [
    "#### Broadcasting a Column Vector to a Matrix\n",
    "Let's see another example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bfd8ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12, 13],\n",
      "        [24, 25, 26],\n",
      "        [37, 38, 39]])\n"
     ]
    }
   ],
   "source": [
    "# A 3x3 matrix\n",
    "matrix = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "# A column vector (3 rows, 1 column)\n",
    "col_vector = torch.tensor([\n",
    "    [10],\n",
    "    [20],\n",
    "    [30]\n",
    "])\n",
    "\n",
    "# Broadcasting: adds col_vector to each column of the matrix\n",
    "result = matrix + col_vector\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada661e",
   "metadata": {},
   "source": [
    "In this example, we add a 3×1 column vector to a 3×3 matrix. PyTorch automatically broadcasts the column vector along the second dimension (columns), so it gets added to each row:\n",
    "\n",
    "- Matrix shape: `(3, 3)`\n",
    "- Column vector shape: `(3, 1)`\n",
    "\n",
    "PyTorch expands the column vector to match the shape of the matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f237ae64",
   "metadata": {},
   "source": [
    "```\n",
    "[[10, 10, 10],\n",
    "[20, 20, 20],\n",
    "[30, 30, 30]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d1fc3",
   "metadata": {},
   "source": [
    "\n",
    "And then adds it element-wise to the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44629c22",
   "metadata": {},
   "source": [
    "## Matrix Multiplication (*dot product*)\n",
    "\n",
    "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication, also referred to as the *dot product*.\n",
    "\n",
    "PyTorch implements matrix multiplication functionality in the [torch.matmul()](https://docs.pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul) method. \n",
    "\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "The inner dimensions must match:\n",
    "```\n",
    "(3, 2) @ (3, 2) # won't work\n",
    "(2, 3) @ (3, 2) # will work\n",
    "(3, 2) @ (2, 3) # will work\n",
    "```\n",
    "The resulting matrix has the shape of the outer dimensions:\n",
    "```\n",
    "(2, 3) @ (3, 2) -> (2, 2)\n",
    "(3, 2) @ (2, 3) -> (3, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c49f1c6",
   "metadata": {},
   "source": [
    "> **Note:** `@` in Python is the symbol for matrix multiplication, but it is recommended to use `.matmul()`, which is way faster.\n",
    "\n",
    "> **Note:** `.mm()` is (almost) an alias for `.matmul()`; there is a difference: `.mm()` works *only for 2D matrices*, while `.matmul()` works with tensors of any dimensiion. Basically, `.mm()` does not broadcast, while `.matmul()` does.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e749a",
   "metadata": {},
   "source": [
    "Let's create a tensor and perform element-wise multiplication and matrix multiplication on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ef1c3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4da72a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise matrix multiplication\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0226e095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd593837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also use the \"@\" symbol for matrix multiplication, though not recommended (slower)\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405faa92",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "torch.mm(tensor, tensor)    # this won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d0dbed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: tensor([[14]])\n",
      "result value: 14\n"
     ]
    }
   ],
   "source": [
    "# to use .mm() with vectors we should manually change shapes (what .matmul() does automatically)\n",
    "tensor1 = tensor.reshape(1,3)\n",
    "tensor2 = tensor.reshape(3,1)\n",
    "result = torch.mm(tensor1, tensor2) # shape (1,1)\n",
    "\n",
    "print(f\"result: {result}\")  #tensor([[14]])\n",
    "print(f\"result value: {result.item()}\") # 14 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2355d2e0",
   "metadata": {},
   "source": [
    "To summarize, for our `tensor` variable with values `[1, 2, 3]`:\n",
    "\n",
    "| Operation                | Calculation                        | Code                     |\n",
    "|--------------------------|------------------------------------|--------------------------|\n",
    "| Element-wise multiplication | `[1*1, 2*2, 3*3] = [1, 4, 9]`      | `tensor * tensor`        |\n",
    "| Matrix multiplication     | `[1*1 + 2*2 + 3*3] = [14]`         | `tensor.matmul(tensor, tensor)`  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f557bc",
   "metadata": {},
   "source": [
    "### Transposition and Reshaping\n",
    "\n",
    "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches.\n",
    "\n",
    "Of course if we are creating tensors \"on the fly\" we could just create them with matching shapes. But what if these tensors already exist and we need to multiply them? For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a876976",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m tensor_A = torch.tensor([[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m],\n\u001b[32m      3\u001b[39m                          [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m],\n\u001b[32m      4\u001b[39m                          [\u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m]], dtype=torch.float32)\n\u001b[32m      6\u001b[39m tensor_B = torch.tensor([[\u001b[32m7\u001b[39m, \u001b[32m10\u001b[39m],\n\u001b[32m      7\u001b[39m                          [\u001b[32m8\u001b[39m, \u001b[32m11\u001b[39m], \n\u001b[32m      8\u001b[39m                          [\u001b[32m9\u001b[39m, \u001b[32m12\u001b[39m]], dtype=torch.float32)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b06a2",
   "metadata": {},
   "source": [
    "We want the inner dimensions to match. In this case we can simply transpose the second matrix. We can do this with \n",
    "- `torch.transpose(input, dim0, dim1)` - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
    "- `tensor.T` - where tensor is the desired tensor to transpose.\n",
    "\n",
    "Let's try the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf304f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7., 10.],\n",
      "        [ 8., 11.],\n",
      "        [ 9., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4ccbb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# View tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6663ed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42b775",
   "metadata": {},
   "source": [
    "Remember, matrix multiplication is the building block of neural networks (that's why the mathematics of deep learning isn't usually that hard). So matrix multiplication is all you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597726c2",
   "metadata": {},
   "source": [
    "![Example of encoding an RGB image](imgs/00_matrix_multiplication_is_all_you_need.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
