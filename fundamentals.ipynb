{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f8bd2834",
      "metadata": {
        "id": "f8bd2834"
      },
      "source": [
        "# PyTorch Fundamentals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b11244bc",
      "metadata": {
        "id": "b11244bc"
      },
      "source": [
        "## Introduction to Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f6697a",
      "metadata": {
        "id": "06f6697a"
      },
      "source": [
        "### The Tensor object\n",
        "\n",
        "At the core of PyTorch lies the `Tensor` object, which serves as the fundamental data structure for all computations. Tensors are multidimensional arrays, conceptually similar to NumPy arrays, but with added capabilities tailored for deep learning and high-performance computing.\n",
        "\n",
        "PyTorch tensors support a wide variety of operations, including arithmetic, indexing, reshaping, and broadcasting. More importantly, they can be transferred seamlessly between the CPU and GPU, allowing for accelerated computation with minimal code changes.\n",
        "\n",
        "In practice, tensors represent everything from scalar values to high-dimensional data such as images, sequences, and model parameters. Understanding tensors and how to manipulate them efficiently is essential for working with PyTorch and developing neural network models.\n",
        "\n",
        "PyTorch tensors are created using [`torch.tensor`](https://pytorch.org/docs/stable/tensors.html). For example, we may create the simplest tensor – a scalar – in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18602581",
      "metadata": {
        "id": "18602581",
        "outputId": "633d2958-2b36-437e-f4d0-ca9abe0daa4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "# scalar\n",
        "scalar = torch.tensor(2)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b431478",
      "metadata": {
        "id": "5b431478"
      },
      "source": [
        "A scalar is a $0$-dimensional tensor. As a matter of fact, we can check its dimension with `ndim`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e539cbae",
      "metadata": {
        "id": "e539cbae",
        "outputId": "9c7c5891-dd38-49e0-b096-e59e772e037a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "124c2e7c",
      "metadata": {
        "id": "124c2e7c"
      },
      "source": [
        "To access the value of a tensor, we must use the `item()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd344d7",
      "metadata": {
        "id": "7fd344d7",
        "outputId": "e7111849-ff89-42b6-ec45-e181a8fc1e7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e600979",
      "metadata": {
        "id": "9e600979"
      },
      "source": [
        "The next structure is just a vector, i.e. a tensor of dimension $2$. We can create it using the torch.tensor() constructor from a simple python list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1909dd9f",
      "metadata": {
        "id": "1909dd9f",
        "outputId": "6d49374b-61e3-4033-b459-db749d8a0464"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2, 7])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vector\n",
        "vector = torch.tensor([2, 7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6b1d1a0",
      "metadata": {
        "id": "f6b1d1a0"
      },
      "source": [
        "Note: be careful using `tensor()` instead of `Tensor()`. The latter is a lower-level class constructor. When given shape arguments (e.g., `torch.Tensor(2, 3)`), it creates an *uninitialized* tensor. This can lead to unintended behavior. So, always use `torch.tensor()` when starting from data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7da9f98",
      "metadata": {
        "id": "d7da9f98"
      },
      "source": [
        "Now, tensors' dimensions and their shapes are very important in PyTorch. When manipulating vectors, we must pay close attention to their shapes, or we may run into errors or miscalculations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f731ba",
      "metadata": {
        "id": "e3f731ba",
        "outputId": "0d32f224-b19e-4408-e0d3-440e6be797aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2b8257a",
      "metadata": {
        "id": "d2b8257a"
      },
      "source": [
        "This is different from vector.shape:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9486433",
      "metadata": {
        "id": "b9486433",
        "outputId": "c208289a-db41-49dc-aed2-045051bf5ba1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7e8b565",
      "metadata": {
        "id": "f7e8b565"
      },
      "source": [
        "We can step things up and create a matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286c2846",
      "metadata": {
        "id": "286c2846",
        "outputId": "9806c0aa-93b3-4999-b4b0-b863e0152514"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [7, 8]])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix = torch.tensor([[1, 2], [7, 8]])\n",
        "matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d80c870",
      "metadata": {
        "id": "9d80c870",
        "outputId": "ea3a71a9-0e84-4cd1-cf75-0ce33fda1f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "matrix dims: 2\n",
            "matrix shape: torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f\"matrix dims: {matrix.ndim}\")\n",
        "print(f\"matrix shape: {matrix.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb50f56e",
      "metadata": {
        "id": "fb50f56e"
      },
      "source": [
        "This tells us that our matrix is 2-dimensional, and in fact it's a 2×2 square matrix. How about a rectangular matrix? Very simple:\n",
        "<!--  -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d20b739",
      "metadata": {
        "id": "1d20b739",
        "outputId": "23107faa-0cfb-4774-d2ed-8ceaf6cc6054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "matrix dims: 2\n",
            "matrix shape: torch.Size([3, 2])\n"
          ]
        }
      ],
      "source": [
        "rect_matrix = torch.tensor([[1, 2], [3, 4], [4, 5]])\n",
        "print(f\"matrix dims: {rect_matrix.ndim}\")\n",
        "print(f\"matrix shape: {rect_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53dfd227",
      "metadata": {
        "id": "53dfd227"
      },
      "source": [
        "Since we have $2$ elements along each axes, and it's a $3\\times2$ matrix.  \n",
        "Let's see how it works with tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e78d97f",
      "metadata": {
        "id": "8e78d97f",
        "outputId": "7d2c9127-2e27-4c77-c9de-8532c453eea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5],\n",
              "         [6, 7, 8]]])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TENSOR\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5],\n",
        "                        [6, 7, 8]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c90cef9",
      "metadata": {
        "id": "4c90cef9",
        "outputId": "54853418-d7d4-43fb-e07d-b95bca4a0276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor dim: 3\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tensor dim: {TENSOR.ndim}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64d4e967",
      "metadata": {
        "id": "64d4e967",
        "outputId": "450b9c3c-b77d-49c4-cdd6-65a36351a81c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor shape: torch.Size([1, 4, 3])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tensor shape: {TENSOR.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff56c5e0",
      "metadata": {
        "id": "ff56c5e0"
      },
      "source": [
        "Why this shape? We can think of tensors as multidimensional matrices. In this case, we have 1 matrix containing 4 vectors of dimension 3.\n",
        "\n",
        "Understanding shapes takes some practice, but once you get used to it, it becomes second nature."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45fa0e38",
      "metadata": {
        "id": "45fa0e38"
      },
      "source": [
        "This represents 2 images, each of size 3×3 pixels, with 3 channels (RGB).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83790a27",
      "metadata": {
        "id": "83790a27"
      },
      "source": [
        "### Random Tensors\n",
        "\n",
        "Random tensors are very important in PyTorch's workflows. The reason is the way Neural Networks work. They start from randomly initialized weights, and they adapt these values through training (by minimizing a Loss function). So the first step is always to intialize weights randomly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b34775a6",
      "metadata": {
        "id": "b34775a6"
      },
      "source": [
        "In order to create random tensors we can use Torch's [torch.rand()](https://docs.pytorch.org/docs/main/generated/torch.rand.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2622a90b",
      "metadata": {
        "id": "2622a90b",
        "outputId": "e049199e-45e3-499a-d6b7-f7b042a913e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random tensor dimension: 2\n",
            "random tensor shape: torch.Size([3, 4])\n"
          ]
        }
      ],
      "source": [
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor\n",
        "print(f\"random tensor dimension: {random_tensor.ndim}\") # dims will be 2\n",
        "print(f\"random tensor shape: {random_tensor.shape}\") # shape will be torch.Size([3,4])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b2f7cc",
      "metadata": {
        "id": "29b2f7cc"
      },
      "source": [
        "A common example of tensor encoding is when we want to encode an image. Usually to encode an image we use a tensor of shapes `[colour_channels, height, width]`. For an RGB image of size `224 x 224`we will use something like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2671288",
      "metadata": {
        "id": "f2671288"
      },
      "source": [
        "![Example of encoding an RGB image](https://github.com/MatteoFalcioni/PyTorch_basics/blob/main/imgs/00-tensor-shape-example-of-image.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bb0ecf4",
      "metadata": {
        "id": "8bb0ecf4"
      },
      "source": [
        "> **Note on REPRODUCIBILITY:** `torch_manual_seed()` allows you to set the seed for random number generations, so that your code becomes reproducible (random numbers will still be random, but they will be the same random number every time - unless you change the seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "287f1baf",
      "metadata": {
        "id": "287f1baf"
      },
      "source": [
        "### 0's and 1's Tensors\n",
        "These are useful for creating masks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ad6985",
      "metadata": {
        "id": "04ad6985",
        "outputId": "33889247-d9ea-442f-cf1e-dae4f8631b67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor of all zeros\n",
        "zeros = torch.zeros(3,4)\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ece2e9",
      "metadata": {
        "id": "06ece2e9",
        "outputId": "0073dac5-272a-4e3e-ece6-6e7f04e231c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor of all zeros\n",
        "ones = torch.ones(3,4)\n",
        "ones"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81a2096f",
      "metadata": {
        "id": "81a2096f"
      },
      "source": [
        "Note: when you let Torch automatically create a tensor, its default type is `torch.float32`. To get the type we can use the `.dtype` argument. We will see more about types in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac44c974",
      "metadata": {
        "id": "ac44c974",
        "outputId": "75113385-5c30-47ef-abfe-1c5669f66702"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ones.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dfd8684",
      "metadata": {
        "id": "9dfd8684"
      },
      "source": [
        "### Creating range of tensors & tensors-like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e880321",
      "metadata": {
        "id": "5e880321",
        "outputId": "970d4151-ec9c-4294-f7b7-eecd246284ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# use torch.range()\n",
        "one_to_Ten = torch.arange(1,11)\n",
        "one_to_Ten"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d91e3f",
      "metadata": {
        "id": "66d91e3f"
      },
      "source": [
        "Basically its parameters are start, end (ends at end-1) and steps. by default the step is $1$ but we can modify it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc1eafd",
      "metadata": {
        "id": "9dc1eafd",
        "outputId": "1be95834-1afb-442a-9afa-b528f32406cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
              "        36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70,\n",
              "        72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zero_to_hundred = torch.arange(start=0, end=100, step=2)\n",
        "zero_to_hundred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecfad46c",
      "metadata": {
        "id": "ecfad46c"
      },
      "source": [
        "Another useful method is the `_like()` method. For example, `zeros_like()`  allows us to create a tensor with the shape of another already existing tensor, all filled with zeros. There are many options, you can fill it with chosen values (`torch.full_like()`) , with random numbers (`torch.rand_like()`), and so on.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a96f56",
      "metadata": {
        "id": "21a96f56",
        "outputId": "64ca2d76-32f3-4a34-8e36-7e698e6c497e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ten_zeros = torch.zeros_like(one_to_Ten)\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11b60249",
      "metadata": {
        "id": "11b60249"
      },
      "source": [
        "### Tensor datatypes\n",
        "\n",
        "The standard type is float32, but we can change it of course by explicitly setting it. See [torch.dtype](https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch-dtype)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf9d149",
      "metadata": {
        "id": "cbf9d149",
        "outputId": "ff0f6a60-63dc-4a65-8a4c-4ad9d875b4b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3513, 0.6349, 0.8420, 0.9925, 0.9101, 0.7914],\n",
              "        [0.1295, 0.1268, 0.9806, 0.1038, 0.3814, 0.0941]])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.rand(2 ,6)\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c872521",
      "metadata": {
        "id": "9c872521",
        "outputId": "c98edc13-fcf8-4b17-b282-49c195182e43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92525e01",
      "metadata": {
        "id": "92525e01",
        "outputId": "accdfe85-bc9f-4b3b-a43f-3bb1e61b6af5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Float 16 tensor\n",
        "float_16_tensor = torch.rand((2 ,6), dtype=torch.float16)\n",
        "float_16_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c97a714",
      "metadata": {
        "id": "5c97a714"
      },
      "source": [
        "Or, if you are creating a tensor from scratch, you can specify it in the same way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe5c56ce",
      "metadata": {
        "id": "fe5c56ce",
        "outputId": "785de013-6ef4-46e1-8ee1-1ad7e77971ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 3.,  6.,  9., 10.], dtype=torch.float16)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = [3, 6, 9, 10]\n",
        "tensor = torch.tensor(data, dtype=torch.float16)\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58a3f8e1",
      "metadata": {
        "id": "58a3f8e1"
      },
      "source": [
        "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
        "\n",
        "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
        "\n",
        "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51ff7fb",
      "metadata": {
        "id": "a51ff7fb"
      },
      "source": [
        "`.dtype` is one of the three main arguments in the `tensor()` class. The other two are just as important - if not more - and we will see more about them later on. They are the `device` argument, which specify on which device (cpu or gpu) our machine should create our tensor, and `requires_grad`, which specifies if we should keep track of operations performed on our tensor in order to perform backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1334ef97",
      "metadata": {
        "id": "1334ef97",
        "outputId": "3c367347-2af9-493e-f3a7-585001bccfb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.float32, device(type='cpu'), False)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # What dataype is the tensor, defaults to torch.float32 (even if it's set to None)\n",
        "                               device='cpu', # What device is your tensor on\n",
        "                               requires_grad=False) # whether or not to track gradients for backpropagation (default False if not wrapped in nn.Parameter)\n",
        "\n",
        "float_32_tensor.dtype, float_32_tensor.device, float_32_tensor.requires_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58726ce0",
      "metadata": {
        "id": "58726ce0"
      },
      "source": [
        "Operations between types in Torch are robust, meaning that even if two tensors have different types, sometimes this will not raise an error, and revert everything to default (float 32). Nonetheless, you should always be careful to *perform operations between tensors of the same type*, to avoid miscalculations and problems.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f864985",
      "metadata": {
        "id": "7f864985"
      },
      "source": [
        "### Getting Information from Tensors\n",
        "\n",
        "Once you've created tensors (or someone else or a PyTorch module has created them for you), you might want to get some information from them.\n",
        "\n",
        "We've seen these before but three of the most common attributes you'll want to find out about tensors are:\n",
        "- `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
        "- `dtype` - what datatype are the elements within the tensor stored in?\n",
        "- `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
        "\n",
        "Let's create a random tensor and find out details about it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232b4934",
      "metadata": {
        "id": "232b4934",
        "outputId": "41efacf1-1639-4e63-e252-f926f6b17231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3923, 0.4521, 0.5415, 0.3870],\n",
            "        [0.9300, 0.6538, 0.9350, 0.3785],\n",
            "        [0.0193, 0.2008, 0.8574, 0.0714]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# Find out details about it\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "072755ef",
      "metadata": {
        "id": "072755ef"
      },
      "source": [
        "### Basic Operations and Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e724688",
      "metadata": {
        "id": "0e724688"
      },
      "source": [
        "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
        "\n",
        "A model learns by investigating those tensors and performing a series of operations (could be $1,000,000$'s+) on tensors to create a representation of the patterns in the input data.\n",
        "\n",
        "These operations are often a wonderful dance between:\n",
        "\n",
        "- Addition\n",
        "- Substraction\n",
        "- Multiplication (element-wise)\n",
        "- Division\n",
        "- Matrix multiplication\n",
        "\n",
        "And that's it. Sure there are a few more here and there but these are the basic building blocks of neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bb997c3",
      "metadata": {
        "id": "6bb997c3"
      },
      "source": [
        "Let's start with a few of the fundamental operations, addition (`+`), subtraction (`-`), mutliplication (`*`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c976ac5a",
      "metadata": {
        "id": "c976ac5a",
        "outputId": "0ec3c53e-15bf-4a79-b69d-9a2c2ac7c55d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c7f9c3c",
      "metadata": {
        "id": "5c7f9c3c",
        "outputId": "541923f8-7a66-484e-c569-d87f649438ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiply it by 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83b0cf88",
      "metadata": {
        "id": "83b0cf88"
      },
      "source": [
        "Notice how the tensor values above didn't end up being `tensor([110, 120, 130])`, this is because the values inside the tensor don't change unless they're reassigned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45f5eaff",
      "metadata": {
        "id": "45f5eaff",
        "outputId": "0d7ab21d-4628-4cd8-e529-66af42708ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensors don't change unless reassigned\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "864c22ec",
      "metadata": {
        "id": "864c22ec"
      },
      "source": [
        "Let's subtract a number and this time we'll reassign the tensor variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87d24806",
      "metadata": {
        "id": "87d24806",
        "outputId": "e4f0a30f-604f-41cb-e891-fa8a1f5b966a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-19, -18, -17])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subtract and reassign\n",
        "tensor = tensor - 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e5ec29b",
      "metadata": {
        "id": "8e5ec29b",
        "outputId": "067534b7-433d-4027-be9d-c0c999f49067"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add and reassign\n",
        "tensor = tensor + 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81c16c52",
      "metadata": {
        "id": "81c16c52",
        "outputId": "ba07f22f-1169-4704-9a03-c9b8e7a11f07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add and reassign\n",
        "tensor = tensor + 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d165f1e",
      "metadata": {
        "id": "3d165f1e"
      },
      "outputs": [],
      "source": [
        "# Matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f55852",
      "metadata": {
        "id": "06f55852"
      },
      "source": [
        "### *Note on Broadcasting*\n",
        "\n",
        "Broadcasting allows PyTorch to perform operations between tensors of different shapes by automatically expanding the smaller tensor to match the shape of the larger one.\n",
        "\n",
        "For example what we saw above :\n",
        "```python\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f6c755f",
      "metadata": {
        "id": "8f6c755f"
      },
      "source": [
        "PyTorch is *broadcasting* the scalar `10` across all elements of the tensor. Internally, it's as if it expanded `10` to match the shape of tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c309c8b5",
      "metadata": {
        "id": "c309c8b5",
        "outputId": "31e9cf7c-4a6b-4c8e-9600-3c2e86900228"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Equivalent to:\n",
        "torch.tensor([1, 2, 3]) + torch.tensor([10, 10, 10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac6e2f2d",
      "metadata": {
        "id": "ac6e2f2d"
      },
      "source": [
        "#### *Broadcasting a Column Vector to a Matrix*\n",
        "Let's see another example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bfd8ddb",
      "metadata": {
        "id": "4bfd8ddb",
        "outputId": "264877d3-0f2f-45c8-c505-a1debb07a125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[11, 12, 13],\n",
            "        [24, 25, 26],\n",
            "        [37, 38, 39]])\n"
          ]
        }
      ],
      "source": [
        "# A 3x3 matrix\n",
        "matrix = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "])\n",
        "\n",
        "# A column vector (3 rows, 1 column)\n",
        "col_vector = torch.tensor([\n",
        "    [10],\n",
        "    [20],\n",
        "    [30]\n",
        "])\n",
        "\n",
        "# Broadcasting: adds col_vector to each column of the matrix\n",
        "result = matrix + col_vector\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ada661e",
      "metadata": {
        "id": "2ada661e"
      },
      "source": [
        "In this example, we add a 3×1 column vector to a 3×3 matrix. PyTorch automatically broadcasts the column vector along the second dimension (columns), so it gets added to each row:\n",
        "\n",
        "- Matrix shape: `(3, 3)`\n",
        "- Column vector shape: `(3, 1)`\n",
        "\n",
        "PyTorch expands the column vector to match the shape of the matrix:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f237ae64",
      "metadata": {
        "id": "f237ae64"
      },
      "source": [
        "```\n",
        "[[10, 10, 10],\n",
        "[20, 20, 20],\n",
        "[30, 30, 30]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "148d1fc3",
      "metadata": {
        "id": "148d1fc3"
      },
      "source": [
        "\n",
        "And then adds it element-wise to the matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44629c22",
      "metadata": {
        "id": "44629c22"
      },
      "source": [
        "### Matrix Multiplication (*dot product*)\n",
        "\n",
        "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication, also referred to as the *dot product*.\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the [torch.matmul()](https://docs.pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul) method.\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "The inner dimensions must match:\n",
        "```\n",
        "(3, 2) @ (3, 2) # won't work\n",
        "(2, 3) @ (3, 2) # will work\n",
        "(3, 2) @ (2, 3) # will work\n",
        "```\n",
        "The resulting matrix has the shape of the outer dimensions:\n",
        "```\n",
        "(2, 3) @ (3, 2) -> (2, 2)\n",
        "(3, 2) @ (2, 3) -> (3, 3)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c49f1c6",
      "metadata": {
        "id": "1c49f1c6"
      },
      "source": [
        "> **Note:** `@` in Python is the symbol for matrix multiplication, but it is recommended to use `.matmul()`, which is way faster.\n",
        "\n",
        "> **Note:** Sometimes you'll find people using `.mm()` like it is an alias for `.matmul()`. It's not. `.mm()` works *only for 2D matrices*, while `.matmul()` works with tensors of any dimensiion. Basically, `.mm()` does not broadcast, while `.matmul()` does.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c61e749a",
      "metadata": {
        "id": "c61e749a"
      },
      "source": [
        "Let's create a tensor and perform element-wise multiplication and matrix multiplication on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef1c3f4",
      "metadata": {
        "id": "7ef1c3f4",
        "outputId": "9f032b53-6298-4d03-f804-05f88c55d6c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4da72a1",
      "metadata": {
        "id": "c4da72a1",
        "outputId": "8f453bd0-7d60-446f-d724-fe35888562a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Element-wise matrix multiplication\n",
        "tensor * tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0226e095",
      "metadata": {
        "id": "0226e095",
        "outputId": "2248e4da-baf8-4f9c-fde4-85c97e0c16e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd593837",
      "metadata": {
        "id": "bd593837",
        "outputId": "6e1dbe74-ebe3-4a58-c5f0-d69133574791"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Can also use the \"@\" symbol for matrix multiplication, though not recommended (slower)\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "405faa92",
      "metadata": {
        "id": "405faa92",
        "outputId": "ea099f11-9a8e-4d06-9304-037accda650e"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "self must be a matrix",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: self must be a matrix"
          ]
        }
      ],
      "source": [
        "torch.mm(tensor, tensor)    # this won't work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d0dbed6",
      "metadata": {
        "id": "4d0dbed6",
        "outputId": "82394f27-099d-4431-b944-aad87af2eff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "result: tensor([[14]])\n",
            "result value: 14\n"
          ]
        }
      ],
      "source": [
        "# to use .mm() with vectors we should manually change shapes (what .matmul() does automatically)\n",
        "tensor1 = tensor.reshape(1,3)\n",
        "tensor2 = tensor.reshape(3,1)\n",
        "result = torch.mm(tensor1, tensor2) # shape (1,1)\n",
        "\n",
        "print(f\"result: {result}\")  #tensor([[14]])\n",
        "print(f\"result value: {result.item()}\") # 14"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2355d2e0",
      "metadata": {
        "id": "2355d2e0"
      },
      "source": [
        "To summarize, for our `tensor` variable with values `[1, 2, 3]`:\n",
        "\n",
        "| Operation                | Calculation                        | Code                     |\n",
        "|--------------------------|------------------------------------|--------------------------|\n",
        "| Element-wise multiplication | `[1*1, 2*2, 3*3] = [1, 4, 9]`      | `tensor * tensor`        |\n",
        "| Matrix multiplication     | `[1*1 + 2*2 + 3*3] = [14]`         | `tensor.matmul(tensor, tensor)`  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f557bc",
      "metadata": {
        "id": "75f557bc"
      },
      "source": [
        "### Transposition\n",
        "\n",
        "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches.\n",
        "\n",
        "Of course if we are creating tensors \"on the fly\" we could just create them with matching shapes. But what if these tensors already exist and we need to multiply them? For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a876976",
      "metadata": {
        "id": "5a876976",
        "outputId": "febf9b67-4671-4c9e-b6be-bb1a733b47ca"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m tensor_A = torch.tensor([[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m],\n\u001b[32m      3\u001b[39m                          [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m],\n\u001b[32m      4\u001b[39m                          [\u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m]], dtype=torch.float32)\n\u001b[32m      6\u001b[39m tensor_B = torch.tensor([[\u001b[32m7\u001b[39m, \u001b[32m10\u001b[39m],\n\u001b[32m      7\u001b[39m                          [\u001b[32m8\u001b[39m, \u001b[32m11\u001b[39m], \n\u001b[32m      8\u001b[39m                          [\u001b[32m9\u001b[39m, \u001b[32m12\u001b[39m]], dtype=torch.float32)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db6b06a2",
      "metadata": {
        "id": "db6b06a2"
      },
      "source": [
        "We want the inner dimensions to match. In this case we can simply transpose the second matrix. We can do this with\n",
        "- `torch.transpose(input, dim0, dim1)` - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
        "- `tensor.T` - where tensor is the desired tensor to transpose.\n",
        "\n",
        "Let's try the latter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf304f67",
      "metadata": {
        "id": "cf304f67",
        "outputId": "90cfa4af-8f0a-4a31-fae4-dc7d891992d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ],
      "source": [
        "# View tensor_A and tensor_B\n",
        "print(tensor_A)\n",
        "print(tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ccbb95",
      "metadata": {
        "id": "f4ccbb95",
        "outputId": "0df1f0e7-c345-4379-e168-153ef545dfd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ],
      "source": [
        "# View tensor_A and tensor_B.T\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6663ed1f",
      "metadata": {
        "id": "6663ed1f",
        "outputId": "f3ac37f0-5b0e-4118-9382-6d6c6657232e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe42b775",
      "metadata": {
        "id": "fe42b775"
      },
      "source": [
        "Remember, matrix multiplication is the building block of neural networks (that's why the mathematics of deep learning isn't usually that hard). So matrix multiplication is all you need."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597726c2",
      "metadata": {
        "id": "597726c2"
      },
      "source": [
        "![Example of encoding an RGB image](https://github.com/MatteoFalcioni/PyTorch_basics/blob/main/imgs/00_matrix_multiplication_is_all_you_need.jpeg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a5b7d5",
      "metadata": {
        "id": "22a5b7d5"
      },
      "source": [
        "### Finding the min, max, mean, sum, etc (aggregation)\n",
        "\n",
        "Now we've seen a few ways to manipulate tensors, let's run through a few ways to aggregate them (go from more values to less values).\n",
        "\n",
        "First we'll create a tensor and then find the max, min, mean and sum of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6ace3e",
      "metadata": {
        "id": "bc6ace3e",
        "outputId": "a3b5eed5-54d3-4eaa-fc59-cf8a835222ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07523179",
      "metadata": {
        "id": "07523179"
      },
      "source": [
        "Now let's perform some aggregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d1bea7b",
      "metadata": {
        "id": "7d1bea7b",
        "outputId": "93e0460c-66d6-4ad4-ca90-983bc4824db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ],
      "source": [
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # this will error because of the dataype!\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {x.sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ede61bad",
      "metadata": {
        "id": "ede61bad"
      },
      "source": [
        "You may find some methods such as `torch.mean()` require tensors to be in `torch.float32` (the most common) or another specific datatype, otherwise the operation will fail."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20d14e39",
      "metadata": {
        "id": "20d14e39"
      },
      "source": [
        "You can also do the same as above with `torch` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2dd38f1",
      "metadata": {
        "id": "f2dd38f1",
        "outputId": "61cd6002-7aae-48d0-8521-b8feefb32a06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7c353bd",
      "metadata": {
        "id": "c7c353bd"
      },
      "source": [
        "### Changing dataype\n",
        "\n",
        "You can change the datatypes of tensors in different ways. This is the most flexible and recommended way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acd3cc3a",
      "metadata": {
        "id": "acd3cc3a"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1, 2, 3])        # int64 by default\n",
        "x = x.to(dtype=torch.float32)     # converts to float32"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4bd4289",
      "metadata": {
        "id": "c4bd4289"
      },
      "source": [
        "This is equivalent, *at creation*, to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ee98d1",
      "metadata": {
        "id": "50ee98d1"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1, 2, 3], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd68517b",
      "metadata": {
        "id": "cd68517b"
      },
      "source": [
        "Also, you can use these quick and readable shortcuts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20525126",
      "metadata": {
        "id": "20525126",
        "outputId": "5a292ae5-e0db-460f-84c1-548f1ae03f54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "\n",
        "x.float()   # to torch.float32\n",
        "x.double()  # to torch.float64\n",
        "x.int()     # to torch.int32\n",
        "x.long()    # to torch.int64 (default for integers)\n",
        "x.bool()    # to boolean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efcfab11",
      "metadata": {
        "id": "efcfab11"
      },
      "source": [
        "### Reshaping, stacking, (un)squeezing and permuting\n",
        "\n",
        "In PyTorch, tensor shape manipulation is an essential skill. Whether you're preparing data for a neural network or aligning tensor shapes for operations, these four tools are foundational:\n",
        "\n",
        "- `reshape()`: Change the shape of a tensor without changing its data.\n",
        "- `stack()`: Combine multiple tensors along a new dimension.\n",
        "- `squeeze()`: Remove dimensions of size 1.\n",
        "- `unsqueeze()`: Add a dimension of size 1 at a specified position.\n",
        "- `permute()`:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b9997a7",
      "metadata": {
        "id": "0b9997a7"
      },
      "source": [
        "The `reshape()` method changes the tensor's shape as long as the total number of elements stays the same.\n",
        "\n",
        "For example, a tensor with shape `(9,)` can be reshaped to `(3, 3)`, `(1, 9)`, `(9, 1)`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8d5e778",
      "metadata": {
        "id": "d8d5e778",
        "outputId": "fb687cdd-8992-4b72-8eab-5bff4aeb1222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shape: torch.Size([9])\n",
            "Reshaped (3x3):\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(1, 10)  # tensor([1, 2, ..., 9])\n",
        "print(\"Original shape:\", x.shape)\n",
        "\n",
        "reshaped = x.reshape(3, 3)\n",
        "print(\"Reshaped (3x3):\")\n",
        "print(reshaped)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7290505d",
      "metadata": {
        "id": "7290505d"
      },
      "source": [
        "The `view()` function is another way to change the shape of a tensor, like `reshape()`. It returns a tensor with the same data but a different shape — **as long as the tensor is stored in a contiguous chunk of memory**.\n",
        "\n",
        "If it's not contiguous (e.g. after a `transpose()`), you need to call `.contiguous()` before using `view()`.\n",
        "\n",
        "```python\n",
        "x = torch.arange(1, 9)\n",
        "x = x.view(2, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a263f570",
      "metadata": {
        "id": "a263f570"
      },
      "source": [
        "This is equivalent to:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7798bc87",
      "metadata": {
        "id": "7798bc87"
      },
      "outputs": [],
      "source": [
        "x = torch.arange(1, 9).reshape(2, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d86ab2",
      "metadata": {
        "id": "50d86ab2"
      },
      "source": [
        "But `view()` may raise an error if the original tensor is not contiguous:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf798a3f",
      "metadata": {
        "id": "cf798a3f",
        "outputId": "ac37c3bb-2e85-4514-facf-eaaf3fb82a81"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m x = torch.randn(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m)\n\u001b[32m      2\u001b[39m x_t = x.T  \u001b[38;5;66;03m# transpose\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mx_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ❌ may raise error\u001b[39;00m\n\u001b[32m      4\u001b[39m x_t.contiguous().view(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# ✅ safe\u001b[39;00m\n",
            "\u001b[31mRuntimeError\u001b[39m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "x_t = x.T  # transpose\n",
        "x_t.view(-1)  # ❌ may raise error\n",
        "x_t.contiguous().view(-1)  # ✅ safe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c6da6bd",
      "metadata": {
        "id": "3c6da6bd"
      },
      "source": [
        "Also notice that, since view doesn't modify data stored in memory, if we define a new tensor as a view() of a first one, and then modify it, the starting tensor will change as well. An example can be:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904186db",
      "metadata": {
        "id": "904186db",
        "outputId": "1aedc543-1201-4fa9-92dd-a5e2ca463fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[4.4159e-02, 2.0593e-01, 7.1661e-02],\n",
            "        [2.2882e-01, 2.1666e-01, 2.7942e-02],\n",
            "        [1.0000e+02, 1.0000e+02, 1.0000e+02]])\n",
            "tensor([[4.4159e-02, 2.0593e-01, 7.1661e-02, 2.2882e-01, 2.1666e-01, 2.7942e-02,\n",
            "         1.0000e+02, 1.0000e+02, 1.0000e+02]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(1,9)\n",
        "z = x.view(3,3)\n",
        "z[2] = 100\n",
        "print(z)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1bec57",
      "metadata": {
        "id": "0f1bec57"
      },
      "source": [
        "`reshape()` always allocates new memory, so it handles these issues automatically. You should usually prefer it to `view()`, even though the latter would be marginally faster in low level operations.\n",
        "\n",
        "The main advantage of `view()` is memory related: it doesn't allocate new space in memory, instead it gives you a different view of the already existing tensor data. It is very useful when working with tensors occupying a lot of space."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "299cba99",
      "metadata": {
        "id": "299cba99"
      },
      "source": [
        "The `stack()` function joins a sequence of tensors along a new dimension. All tensors must have the same shape.\n",
        "\n",
        "- `dim=0`: stacks vertically (new first dimension)\n",
        "- `dim=1`: stacks horizontally (new second dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b975552e",
      "metadata": {
        "id": "b975552e",
        "outputId": "aeb9a6ce-5bed-47e0-ab0a-ed2167614fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shape: torch.Size([3])\n",
            "Stacked along dim=0  ('orizzontally'):\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Shape: torch.Size([2, 3])\n",
            "\n",
            "Stacked along dim=1 ('vertically'):\n",
            "tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n",
            "Shape: torch.Size([3, 2])\n"
          ]
        }
      ],
      "source": [
        "# Create two tensors of the same shape\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "print(f\"Original shape: {a.shape}\")\n",
        "\n",
        "# Stack along a new dimension (dim=0)\n",
        "stacked = torch.stack((a, b), dim=0)\n",
        "print(\"Stacked along dim=0  ('orizzontally'):\")\n",
        "print(stacked)\n",
        "print(\"Shape:\", stacked.shape)\n",
        "\n",
        "# Stack along another dimension (dim=1)\n",
        "stacked_dim1 = torch.stack((a, b), dim=1)\n",
        "print(\"\\nStacked along dim=1 ('vertically'):\")\n",
        "print(stacked_dim1)\n",
        "print(\"Shape:\", stacked_dim1.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7a8efe8",
      "metadata": {
        "id": "d7a8efe8"
      },
      "source": [
        "The `squeeze()` method removes all dimensions with size 1. It's useful when a model or operation adds unnecessary singleton dimensions.\n",
        "\n",
        "You can also specify a dimension to squeeze with `squeeze(dim=...)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8a2f41",
      "metadata": {
        "id": "6c8a2f41",
        "outputId": "ac67faef-1966-402f-9ac5-760f364f08d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shape: torch.Size([1, 3, 1, 5])\n",
            "Squeezed shape: torch.Size([3, 5])\n"
          ]
        }
      ],
      "source": [
        "x = torch.zeros(1, 3, 1, 5)\n",
        "print(\"Original shape:\", x.shape)\n",
        "\n",
        "squeezed = x.squeeze()\n",
        "print(\"Squeezed shape:\", squeezed.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f6fb1f",
      "metadata": {
        "id": "60f6fb1f"
      },
      "source": [
        "The `unsqueeze()` method adds a dimension of size 1 at a given position. This is useful for aligning shapes or preparing inputs for batch operations.\n",
        "\n",
        "Common uses:\n",
        "- Converting shape `(N,)` → `(1, N)` or `(N, 1)`\n",
        "- Making tensors compatible with broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca933fcd",
      "metadata": {
        "id": "ca933fcd",
        "outputId": "a01675a4-31aa-44d7-a052-bd6e7e0a4fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shape: torch.Size([3])\n",
            "Shape after unsqueeze(0): torch.Size([1, 3])\n",
            "Shape after unsqueeze(1): torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "y = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(\"Original shape:\", y.shape)\n",
        "\n",
        "# Add dimension at position 0\n",
        "y_unsq0 = y.unsqueeze(0)\n",
        "print(\"Shape after unsqueeze(0):\", y_unsq0.shape)\n",
        "\n",
        "# Add dimension at position 1\n",
        "y_unsq1 = y.unsqueeze(1)\n",
        "print(\"Shape after unsqueeze(1):\", y_unsq1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4771300",
      "metadata": {
        "id": "d4771300"
      },
      "source": [
        "The `permute()` function allows you to **rearrange the dimensions** of a tensor in any order you want. It does not change the data — only how the data is viewed in memory.\n",
        "\n",
        "This is especially useful when working with image data, where different libraries may expect different dimension orders (e.g., channels-first vs channels-last).\n",
        "\n",
        "---\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Suppose you have an image tensor with shape `(height, width, channels)` — common in libraries like NumPy or PIL — and you want to convert it to PyTorch’s expected format `(channels, height, width)`.\n",
        "\n",
        "You can use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ef8810",
      "metadata": {
        "id": "f7ef8810"
      },
      "outputs": [],
      "source": [
        "image = torch.rand(64, 64, 3)  # HWC format\n",
        "image_permuted = image.permute(2, 0, 1)  # CHW format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9e6035c",
      "metadata": {
        "id": "b9e6035c"
      },
      "source": [
        "So it works like this:\n",
        "```\n",
        "Original shape: (D0, D1, D2)\n",
        "tensor.permute(1, 2, 0) → shape becomes (D1, D2, D0)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df807a33",
      "metadata": {
        "id": "df807a33"
      },
      "source": [
        "Careful: `permute()` returns a **view** of our tensor - it doesn't copy data. Also you cannot use `.view()` after `permute()` unless you call `.contiguous()`, because permuting may create a non-contigous tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42a66bf",
      "metadata": {
        "id": "b42a66bf"
      },
      "source": [
        "### Selecting Data (Indexing)\n",
        "\n",
        "Sometimes you'll want to select specific data from tensors (for example, only the first column or second row).\n",
        "\n",
        "To do so, you can use indexing.\n",
        "\n",
        "If you've ever done indexing on Python lists or NumPy arrays, indexing in PyTorch with tensors is very similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a3e119",
      "metadata": {
        "id": "16a3e119",
        "outputId": "28f47bf6-ed37-41e8-b530-3787daf86654"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 1,  2,  3],\n",
              "          [ 4,  5,  6],\n",
              "          [ 7,  8,  9]],\n",
              " \n",
              "         [[10, 11, 12],\n",
              "          [13, 14, 15],\n",
              "          [16, 17, 18]],\n",
              " \n",
              "         [[19, 20, 21],\n",
              "          [22, 23, 24],\n",
              "          [25, 26, 27]]]),\n",
              " torch.Size([3, 3, 3]))"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 28).reshape(3, 3, 3)    # 3 matrices of size 3x3\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca347f9c",
      "metadata": {
        "id": "ca347f9c"
      },
      "source": [
        "\n",
        "Indexing values goes outer dimension -> inner dimension (check out the square brackets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d80b18f",
      "metadata": {
        "id": "4d80b18f",
        "outputId": "2ccd0d69-8364-4e06-b773-a2e422a196a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ],
      "source": [
        "# Let's index bracket by bracket\n",
        "print(f\"First square bracket:\\n{x[0]}\") # first matrix\n",
        "print(f\"Second square bracket: {x[0][0]}\") # first line (vector) of first matrix\n",
        "print(f\"Third square bracket: {x[0][0][0]}\") # first element of first matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a42aad19",
      "metadata": {
        "id": "a42aad19"
      },
      "source": [
        "Indexing in PyTorch is consistent with how tensors are indexed mathematically. For example, a tensor with three dimensions can be represented as a quantity with indices $T_{ijk}$.  \n",
        "\n",
        "However, remember that **Python uses 0-based indexing**, so:\n",
        "- $T_{0jk}$ refers to the **first matrix**,\n",
        "- $T_{00k}$ refers to the **first row (vector) of the first matrix**,\n",
        "- and so on.\n",
        "\n",
        "This correspondence makes tensor indexing intuitive once you're familiar with the dimensional structure."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4587a293",
      "metadata": {
        "id": "4587a293"
      },
      "source": [
        "You can also use `:` to specify \"all values in this dimension\" and then use a comma `(,)` to add another dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2e3ae7",
      "metadata": {
        "id": "cd2e3ae7",
        "outputId": "698bd3b3-4a91-4a00-b6c8-1b7320636794"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3],\n",
              "        [10, 11, 12],\n",
              "        [19, 20, 21]])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:, 0]  # all of dimension 0 (first matrix). In other words: from all matrices, select the 0th element (first matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c4a17ea",
      "metadata": {
        "id": "0c4a17ea",
        "outputId": "cde3f66a-494e-4fb6-9b3b-cffdcda4f339"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 2,  5,  8],\n",
              "        [11, 14, 17],\n",
              "        [20, 23, 26]])"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:, :, 1]  # Get all values indexed 1 in the third dimension. The third dimension selects\n",
        "            # lines (horizontal vectors) out of our matrices. So we are selecting the middle value from each row"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fee5dfda",
      "metadata": {
        "id": "fee5dfda"
      },
      "source": [
        "In oher words, from all matrices (first `:`) and all vectors (second `:`) select element indexed `1` (the middle one in this case because of dimension $3$).\n",
        "\n",
        "Another example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e8e7ba",
      "metadata": {
        "id": "25e8e7ba",
        "outputId": "98a2e133-c690-47f1-e93d-1d31ad65e941"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 5, 14, 23])"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[:, 1, 1] # from all matrices, select the index 1 vector and from each of these select the index 1 element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7505237",
      "metadata": {
        "id": "e7505237",
        "outputId": "36618712-e738-4a3a-bbf4-0833bfd349cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0, 0, :] # from matrix 0, select 0th vector (orizontal), and take all elements"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd8dda5b",
      "metadata": {
        "id": "dd8dda5b"
      },
      "source": [
        "### PyTorch and NumPy\n",
        "\n",
        "PyTorch has functionality to interact with NumPy nicely.\n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "- `torch.from_numpy(ndarray)` : NumPy array -> PyTorch tensor.\n",
        "- `torch.Tensor.numpy()`: PyTorch tensor -> NumPy array.\n",
        "\n",
        "Let's try them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47694bdf",
      "metadata": {
        "id": "47694bdf",
        "outputId": "d2406f56-66e4-45b6-fdff-484eed347d3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6804a7ea",
      "metadata": {
        "id": "6804a7ea"
      },
      "source": [
        "> **Note:** By default, NumPy arrays are created with the datatype `float64` if not explicitly set to other types. If you convert it to a PyTorch tensor, it'll keep the same datatype (as above). However, many PyTorch calculations default to using `float32`. So if you want to convert your NumPy array (`float64`) -> PyTorch tensor (`float64`) -> PyTorch tensor (`float32`), you can use `tensor = torch.from_numpy(array).to_(dtype=torch.float32)`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffbeb794",
      "metadata": {
        "id": "ffbeb794"
      },
      "source": [
        "Because we reassigned `tensor` above, if you change the tensor, the array stays the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b173cd",
      "metadata": {
        "id": "86b173cd",
        "outputId": "7e4852fd-d562-4a0e-f5ab-cdcd0a7720c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the array, keep the tensor\n",
        "array = array + 1\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "474871d8",
      "metadata": {
        "id": "474871d8"
      },
      "source": [
        "And if you want to go from PyTorch tensor to NumPy array, you can call `tensor.numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4003b410",
      "metadata": {
        "id": "4003b410",
        "outputId": "fa85019b-34e4-4e27-e297-b67ed2af14b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd3bb2ce",
      "metadata": {
        "id": "fd3bb2ce"
      },
      "source": [
        "As above, the two structures are independent. Changing one won't affect the other."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae94f26",
      "metadata": {
        "id": "3ae94f26"
      },
      "source": [
        "## Running Torch on GPU\n",
        "\n",
        "Once you've got a GPU ready to access, the next step is getting PyTorch to use for storing data (tensors) and computing on data (performing operations on tensors).\n",
        "\n",
        "To do so, you can use the `torch.cuda` package.\n",
        "\n",
        "Rather than talk about it, let's try it out.\n",
        "\n",
        "You can test if PyTorch has access to a GPU using `torch.cuda.is_available()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f4f60085",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4f60085",
        "outputId": "bd9d9a12-a04c-4a36-f17b-419ccf7d7e11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a01aa36",
      "metadata": {
        "id": "1a01aa36"
      },
      "source": [
        "If the above outputs `True`, PyTorch can see and use the GPU, if it outputs `False`, it can't see the GPU and in that case, you'll have to go back through the installation steps.\n",
        "\n",
        "Now, let's say you wanted to setup your code so it ran on CPU or the GPU if it was available.\n",
        "\n",
        "That way, if you or someone decides to run your code, it'll work regardless of the computing device they're using.\n",
        "\n",
        "Let's create a `device` variable to store what kind of device is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "03fa220a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "03fa220a",
        "outputId": "3d12c060-1ca4-4ba4-ca31-9d4917efc523"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa944926",
      "metadata": {
        "id": "aa944926"
      },
      "source": [
        "If the above output `\"cuda\"` it means we can set all of our PyTorch code to use the available CUDA device (a GPU) and if it output `\"cpu\"`, our PyTorch code will stick with the CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faa7f56d",
      "metadata": {
        "id": "faa7f56d"
      },
      "source": [
        "> **Note:** In PyTorch, it's best practice to write device agnostic code. This means code that'll run on CPU (always available) or GPU (if available)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad850704",
      "metadata": {
        "id": "ad850704"
      },
      "source": [
        "If you want to do faster computing you can use a GPU but if you want to do much faster computing, you can use multiple GPUs.\n",
        "\n",
        "You can count the number of GPUs PyTorch has access to using `torch.cuda.device_count()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ea5f854c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea5f854c",
        "outputId": "9f19f67c-1487-42cb-ae45-0ec6af3343f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27dfcc3b",
      "metadata": {
        "id": "27dfcc3b"
      },
      "source": [
        "\n",
        "Knowing the number of GPUs PyTorch has access to is helpful incase you wanted to run a specific process on one GPU and another process on another (PyTorch also has features to let you run a process across all GPUs)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8165e8b8",
      "metadata": {
        "id": "8165e8b8"
      },
      "source": [
        "### Putting tensors (and models) on the GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3243f38",
      "metadata": {
        "id": "f3243f38"
      },
      "source": [
        "You can put tensors (and models, we'll see this later) on a specific device by calling `to(device)` on them. Where device is the target device you'd like the tensor (or model) to go to.\n",
        "\n",
        "Why do this?\n",
        "\n",
        "GPUs offer far faster numerical computing than CPUs do and if a GPU isn't available, because of our device agnostic code (see above), it'll run on the CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c40c0ae",
      "metadata": {
        "id": "8c40c0ae"
      },
      "source": [
        "> **Note:** Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them: ` some_tensor = some_tensor.to(device) `"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8beb9c30",
      "metadata": {
        "id": "8beb9c30"
      },
      "source": [
        "Let's try creating a tensor and putting it on the GPU (if it's available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2d6a0d28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d6a0d28",
        "outputId": "72ef14b7-d137-4075-d628-ff5fa7c4c514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1161e7c",
      "metadata": {
        "id": "f1161e7c"
      },
      "source": [
        "If you have a GPU available, the above code will output something like:\n",
        "```\n",
        "tensor([1, 2, 3]) cpu\n",
        "tensor([1, 2, 3], device='cuda:0')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782c2d03",
      "metadata": {
        "id": "782c2d03"
      },
      "source": [
        "Notice the second tensor has `device='cuda:0'`, this means it's stored on the 0th GPU available (GPUs are 0 indexed, if two GPUs were available, they'd be `'cuda:0'` and `'cuda:1'` respectively, up to `'cuda:n'`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7e6dd73",
      "metadata": {
        "id": "d7e6dd73"
      },
      "source": [
        "### Moving tensors back to CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1675777e",
      "metadata": {
        "id": "1675777e"
      },
      "source": [
        "What if we wanted to move the tensor back to CPU?\n",
        "\n",
        "For example, you'll want to do this if you want to interact with your tensors with NumPy (NumPy does not leverage the GPU).\n",
        "\n",
        "Let's try using the `torch.Tensor.numpy()` method on our tensor_on_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "tcQEgkny8Kqy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "tcQEgkny8Kqy",
        "outputId": "43824a19-44fb-4aea-90f7-97bbd8ffbf81"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-53175578f49e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
        "tensor_on_gpu.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Cczh5KNt8MVj",
      "metadata": {
        "id": "Cczh5KNt8MVj"
      },
      "source": [
        "Instead, to get a tensor back to CPU and usable with NumPy we can use `Tensor.cpu()`.\n",
        "\n",
        "This copies the tensor to CPU memory so it's usable with CPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ChMMMjFo8smI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChMMMjFo8smI",
        "outputId": "70d1541c-eebd-49ba-d3dc-4b0eea7d5d84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LdQa16ES8wdj",
      "metadata": {
        "id": "LdQa16ES8wdj"
      },
      "source": [
        "The above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "qXMHP_cY84wa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXMHP_cY84wa",
        "outputId": "7ffde8d5-4984-41ff-b7c0-46967c3fd6ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_on_gpu"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
